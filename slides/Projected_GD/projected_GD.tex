\documentclass{beamer}

\input{../../shared_slides.tex}

\title{Projected Gradient Descent}

\begin{document}
\maketitle
\frame{\tableofcontents}

\section{Introduction}%



\begin{frame}
  \frametitle{Constrained Optimization}

  \begin{minipage}{0.5\textwidth}
    \begin{block}{Constrained optimization problem}
      \begin{equation}
        \begin{aligned}
          \text{minimize } & f(x)\\
          \text{subject to } & x\in C
        \end{aligned}
      \end{equation}
      \textcolor{blue}{How to solve them}
      \begin{itemize}
        \item Project onto $C$
        \item transform to \textit{unconstrained problem}
      \end{itemize}
    \end{block}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{constrained_3d}
      % \caption{\label{fig:label} }
    \end{figure}
  \end{minipage}
\end{frame}


\begin{frame}
  \frametitle{Constrained Optimization}

  \begin{minipage}{0.5\textwidth}
    \begin{block}{Constrained optimization problem}
      \begin{equation}
        \begin{aligned}
          \text{minimize } & f(x)\\
          \text{subject to } & x\in C
        \end{aligned}
      \end{equation}
      \end{block}
      \textcolor{blue}{We will focus on:}
      \begin{itemize}
        \item \textbf{Projected Gradient Descent}
      \end{itemize}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{constrained_3d}
      % \caption{\label{fig:label} }
    \end{figure}
  \end{minipage}
\end{frame}


\begin{frame}
  \frametitle{Projected Gradient Descent}

  \textcolor{blue}{Idea:} After every step project back onto the set: $\Pi_C(x) :=\argmin_{y\in C} \Vert y-x \Vert$.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth,height=0.7\textheight,keepaspectratio]{test}
      % \caption{\label{fig:label} }
    \end{figure}

\end{frame}


\begin{frame}
  \frametitle{Projected subgradient method}
  \begin{equation}
    \text{(constrained setting)} \quad \min_{x\in C}\, f(x)
  \end{equation}
  \begin{algorithm}[H]
    \caption{Projected subgradient method}\label{label:}
    \begin{algorithmic}[1]
      \For{$k=0, 1, \dots$}
      \State{Pick $g_k \in \partial f(x_k)$}
      \State{$y_{k+1} =  x_k- \alpha g_k $}
      \State{$x_{k+1} = \Pi_C(y_{k+1})$}
      \EndFor
    \end{algorithmic}
  \end{algorithm}
\end{frame}


\begin{frame}
  \frametitle{Properties of the Projection}
  \begin{block}{Fact}
    Let $C\subseteq \R^d$ be closed and convex, $x\in C$ and $y \in \R^d$.Then
    \begin{itemize}
      \item $\langle x- \Pi_C(y), y - \Pi_C(y)  \rangle \le 0$
      \item $\Vert x - \Pi_C(y) \Vert^2 + \Vert y - \Pi_c(y) \Vert^2 \le \Vert y-x \Vert^2$
    \end{itemize}
  \end{block}
  \begin{figure}[ht]
    \centering
    \includegraphics[height=0.5\textheight,keepaspectratio]{projection_property}
    % \caption{\label{fig:label} }
  \end{figure}

\end{frame}


\begin{frame}
  \frametitle{Properties of the Projection}
  \begin{block}{Fact}
    Let $C\subseteq \R^d$ be closed and convex, $x\in C$ and $y \in \R^d$.Then
    \begin{itemize}
      \item $\langle x- \Pi_C(y), y - \Pi_C(y)  \rangle \le 0$
      \item $\Vert x - \Pi_C(y) \Vert^2 + \Vert y - \Pi_c(y) \Vert^2 \le \Vert y-x \Vert^2$
    \end{itemize}
  \end{block}
  \begin{proof}
    Since $\Pi_C(x)$ is the minimizer of a differentiable convex function $d_x(y) =\frac12 \Vert y-x \Vert^2$ over $C$, by the \textbf{first-order optimality condition}
    \begin{align}
      0 &\le \langle \nabla d_x(\Pi_C(x)), y - \Pi_C(x) \rangle \\
        &= \langle \Pi_C(x) - x, y - \Pi_C(x) \rangle
    \end{align}
  \end{proof}
\end{frame}



\begin{frame}
  \frametitle{Results for projected GD}

\end{frame}



\begin{frame}
  \frametitle{Projected subgradient method II}
  \begin{proof}
    We can deduce the exact same inequality as before
    \begin{equation}
      \begin{aligned}
        \Vert x_{k+1} - x^* \Vert^2 &= \Vert \Pi_C(x_k - \alpha g_k) - \Pi_C(x^*) \Vert^2 \\
        &\le \Vert x_k - \alpha g_k - x^* \Vert^2 \\
        &= \Vert x_k-x^* \Vert^2 + 2 \alpha \langle g_k, x^*-x_k \rangle + \alpha^2 \Vert g_k \Vert^2\\
        &\le \Vert x_k-x^* \Vert^2 + 2 \alpha (f^* - f(x_k))+ \alpha^2 \Vert g_k \Vert^2.
      \end{aligned}
    \end{equation}
  \end{proof}

\end{frame}




\end{document}
